{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Covid Stream Tristate\n",
    "\n",
    "* From the docs: The streaming API uses the following heuristic to determine whether a given Tweet falls within a bounding box:\n",
    "    * If the coordinates field is populated, the values there will be tested against the bounding box. Note that this field uses geoJSON order (longitude, latitude).\n",
    "    * If coordinates is empty but place is populated, the region defined in place is checked for intersection against the locations bounding box. Any overlap will match.\n",
    "    * If none of the rules listed above match, the Tweet does not match the location query. Note that the geo field is deprecated, and ignored by the streaming API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_rows',200)\n",
    "pd.set_option('precision',4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access credentials\n",
    "CONSUMER_KEY=\"REDACTED\"\n",
    "CONSUMER_SECRET=\"REDACTED\"\n",
    "ACCESS_KEY=\"REDACTED\"\n",
    "ACCESS_SECRET=\"REDACTED\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_PATH = '/home/ubuntu/covid/twitter/'\n",
    "DATA_PATH = BASE_PATH + 'data/'\n",
    "RAW_DATA_PATH = DATA_PATH + 'raw_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "DEFAULT_SLEEP = 60\n",
    "STREAM_FILTERS = ['bb','kw']\n",
    "DATA_FILTERS = ['kw']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "GENERAL_TERMS = ['COVID','COVID19','covid_19','COVIDー19','COVID2019','Covid19us','2019-nCoV','COVD19','CODVID19','Covid-19',\n",
    " 'nCoV2019','covid2020','Covid19pandemic','covid19out','covidkindness','covidiot','covidiots','Knowcovid','SARSCoV2',\n",
    " 'corona','coronavirus','coronovirus','coronaviruspandemic','Coronaeffect','coronavirususa','coronavirusoutbreak',\n",
    " 'coronavirusupdate','Coronapocalypse','coronapocolypse','CoronaOutbreak','the \\’rona','the roni','virus','Pandemic',\n",
    " 'MyPandemicSurvivalPlan','PreventEpidemics','publichealth','flattenthecurve','Quarantine','Quarantinelife',\n",
    " 'quarantineactivities','Quarentineandchill','QuarantineAndChill','SocialDistancing','socialdistancingnow',\n",
    " 'selfisolating','HarmReduction','LockDownSA','lockdowneffect','lockdownextension','lockdowndiaries','Stayhome',\n",
    " 'istayhome','istayathome','Stayathome','StayTheFHome','stayhomestaysafe','StayAtHomeSaveLives','stayhomesavelives',\n",
    " 'iwillsurvivechallenge','StayAtHomeChallenge','ViewFromMyWindow','TogetherAtHome','Withme','Alonetogether',\n",
    " 'inthistogether','untiltomorrow','ImDoingFineBecause','Staysafe','see10send10','seeapupsendapup','Safehands',\n",
    " 'handwashing','Handwashing','washyourhands','workfromhome','Peoplehavetowork','essentialworkers',\n",
    " 'ThanksHealthHeroes','healthcareheroes','GetMePPE','Mask','facemasks','Pdoh','Sdoh','hiap']\n",
    "GENERAL_TERMS = [word.lower() for word in GENERAL_TERMS]\n",
    "\n",
    "FOOD_TERMS = ['TooSmallToFail','SaveAmericanHospitality','SaveRestaurants','RestaurantRecovery',\n",
    "              'ReliefForRestaurants','RallyForRestaurants','SupportLocalRestaurants','SupportLocal',\n",
    "              'SupportLocalBusiness','TheGreatAmericanTakeout','CarryOut','OrderIn','CurbSide','CurbSidePickup',\n",
    "              'DineLocal','StillOpen','WereOpen']\n",
    "FOOD_TERMS = [word.lower() for word in FOOD_TERMS]\n",
    "\n",
    "POLITICAL_TERMS = ['trumpownseverydeath','Trumpliedpeopledied','Trumpliesamericansdie','trumpliespeopledie',\n",
    "                   'Wisconsinpandemicvoting','Trumpgenocide','trumppandemic','gopgenocide']\n",
    "POLITICAL_TERMS = [word.lower() for word in POLITICAL_TERMS]\n",
    "\n",
    "STIGMA_TERMS = ['HateIsAVirus','WashTheHate','RacismIsAVirus','IAmNotCOVID19']\n",
    "STIGMA_TERMS = [word.lower() for word in STIGMA_TERMS]\n",
    "\n",
    "CONSPIRACY_TERMS = ['filmyourhospital','filmyourhospitals','filmyourhospitalchallenge','emptyhospital','dempanic',\n",
    "                    'plandemic','5gkills','5gconspiracy']\n",
    "CONSPIRACY_TERMS = [word.lower() for word in CONSPIRACY_TERMS]\n",
    "\n",
    "SEARCH_TERMS = GENERAL_TERMS+FOOD_TERMS+POLITICAL_TERMS+STIGMA_TERMS+CONSPIRACY_TERMS\n",
    "SEARCH_TERMS_LOWER = [word.lower() for word in SEARCH_TERMS]\n",
    "SEARCH_STRING = '|'.join(SEARCH_TERMS).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_KEY, ACCESS_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class and Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomStreamListener(tweepy.StreamListener):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def on_status(self, status):\n",
    "        # Filter tweets by keyword\n",
    "        if 'extended_tweet' in status._json.keys():\n",
    "            tweet_text = status._json['extended_tweet']['full_text'].lower()\n",
    "        else:\n",
    "            tweet_text = status.text.lower()\n",
    "        keywords = [word for word in SEARCH_TERMS_LOWER if word in tweet_text]\n",
    "        if len(keywords) > 0:\n",
    "            process_tweet(status,keywords)\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print('Encountered error with status code:', status_code, file=sys.stderr)\n",
    "        return True # Don't kill the stream\n",
    "\n",
    "    def on_timeout(self):\n",
    "        print('Timeout...',file=sys.stderr)\n",
    "        return True # Don't kill the stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(status, keywords=None):\n",
    "    print('Collecting status data...')\n",
    "    status_json = json.dumps(status._json)\n",
    "    keyword_str = ','.join(keywords)\n",
    "    pd.DataFrame([[status_json,keyword_str]]).to_csv(RAW_DATA_PATH+'raw_data.csv', mode='a', header=False)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program\n",
    "* Bounding box filter for philadelphia-tristate area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(True):\n",
    "    try:\n",
    "        sapi = tweepy.streaming.Stream(auth, CustomStreamListener())    \n",
    "        sapi.filter(locations=[-75.9814453125,39.53370327008705,-74.37744140625,40.43858586704331])\n",
    "    except:\n",
    "        print('Connection interrupted! Sleeping for', DEFAULT_SLEEP, 'seconds...')\n",
    "        time.sleep(DEFAULT_SLEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS cost calculations for US stream\n",
    "days=365\n",
    "ingress = 150 # gb/day\n",
    "\n",
    "glacier_cost_ammortized=0\n",
    "standard_cost_ammortized=0\n",
    "\n",
    "gb_month_glacier = 0.00099 # $/gb-month\n",
    "gb_month_standard = 0.023\n",
    "\n",
    "gb_day_cost_glacier = (gb_month_glacier/30)\n",
    "gb_day_cost_standard = (gb_month_standard/30)\n",
    "\n",
    "day_cost_glacier = gb_day_cost_glacier*ingress\n",
    "day_cost_standard = gb_day_cost_standard*ingress\n",
    "\n",
    "for i in range(1,days):\n",
    "    glacier_cost_ammortized+= day_cost_glacier*i\n",
    "    standard_cost_ammortized+=day_cost_standard*i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glacier: Ammortized\n",
      "Avg. Monthly Cost: 27.402375000000006\n",
      "Total Cost: 328.8285000000001\n"
     ]
    }
   ],
   "source": [
    "print('Glacier: Ammortized')\n",
    "print('Avg. Monthly Cost:',glacier_cost_ammortized/12)\n",
    "print('Total Cost:',glacier_cost_ammortized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glacier: Bulk\n",
      "Avg. Monthly Cost: 54.2025\n",
      "Total Cost: 650.4300000000001\n"
     ]
    }
   ],
   "source": [
    "print('Glacier: Bulk')\n",
    "print('Avg. Monthly Cost:',ingress*days*gb_month_glacier)\n",
    "print('Total Cost:',ingress*days*gb_month_glacier*12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard: Ammortized\n",
      "Avg. Monthly Cost: 636.6208333333333\n",
      "Total Cost: 7639.45\n"
     ]
    }
   ],
   "source": [
    "print('Standard: Ammortized')\n",
    "print('Avg. Monthly Cost:',standard_cost_ammortized/12)\n",
    "print('Total Cost:',standard_cost_ammortized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard: Bulk\n",
      "Avg. Monthly Cost: 1259.25\n",
      "Total Cost: 15111.0\n"
     ]
    }
   ],
   "source": [
    "print('Standard: Bulk')\n",
    "print('Avg. Monthly Cost:',ingress*days*gb_month_standard)\n",
    "print('Total Cost:',ingress*days*gb_month_standard*12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unused / Deprecated Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
