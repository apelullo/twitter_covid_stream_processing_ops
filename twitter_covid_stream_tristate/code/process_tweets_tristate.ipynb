{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Tweet Data\n",
    "* Process raw tweet data collected from tweepy streaming api\n",
    "* Data is a csv with **status** column encoded as a JSON string and additional columns recording search criteria\n",
    "* LDA topic modeling via mallet on WWBP server - results in output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "pd.set_option('display.max_columns',100)\n",
    "pd.set_option('display.max_rows',200)\n",
    "pd.set_option('precision',4)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Program Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "BASE_PATH = '/Users/arthurpelullo/Desktop/code/CDH/covid/twitter/'\n",
    "DATA_PATH = BASE_PATH + 'data/'\n",
    "RAW_DATA_PATH = DATA_PATH + 'raw_data/'\n",
    "MASTER_DATA_PATH = DATA_PATH + 'master_data/'\n",
    "SUMMARY_DATA_PATH = DATA_PATH + 'summary_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credentials\n",
    "consumer_key=\"REDACTED\"\n",
    "consumer_secret=\"REDACTED\"\n",
    "access_key=\"REDACTED\"\n",
    "access_secret=\"REDACTED\"\n",
    "\n",
    "# authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "GENERAL_TERMS = ['COVID','COVID19','covid_19','COVID„Éº19','COVID2019','Covid19us','2019-nCoV','COVD19','CODVID19','Covid-19',\n",
    " 'nCoV2019','covid2020','Covid19pandemic','covid19out','covidkindness','covidiot','covidiots','Knowcovid','SARSCoV2',\n",
    " 'corona','coronavirus','coronovirus','coronaviruspandemic','Coronaeffect','coronavirususa','coronavirusoutbreak',\n",
    " 'coronavirusupdate','Coronapocalypse','coronapocolypse','CoronaOutbreak','the \\‚Äôrona','the roni','virus','Pandemic',\n",
    " 'MyPandemicSurvivalPlan','PreventEpidemics','publichealth','flattenthecurve','Quarantine','Quarantinelife',\n",
    " 'quarantineactivities','Quarentineandchill','QuarantineAndChill','SocialDistancing','socialdistancingnow',\n",
    " 'selfisolating','HarmReduction','LockDownSA','lockdowneffect','lockdownextension','lockdowndiaries','Stayhome',\n",
    " 'istayhome','istayathome','Stayathome','StayTheFHome','stayhomestaysafe','StayAtHomeSaveLives','stayhomesavelives',\n",
    " 'iwillsurvivechallenge','StayAtHomeChallenge','ViewFromMyWindow','TogetherAtHome','Withme','Alonetogether',\n",
    " 'inthistogether','untiltomorrow','ImDoingFineBecause','Staysafe','see10send10','seeapupsendapup','Safehands',\n",
    " 'handwashing','Handwashing','washyourhands','workfromhome','Peoplehavetowork','essentialworkers',\n",
    " 'ThanksHealthHeroes','healthcareheroes','GetMePPE','Mask','facemasks','Pdoh','Sdoh','hiap']\n",
    "GENERAL_TERMS = [word.lower() for word in GENERAL_TERMS]\n",
    "\n",
    "FOOD_TERMS = ['TooSmallToFail','SaveAmericanHospitality','SaveRestaurants','RestaurantRecovery',\n",
    "              'ReliefForRestaurants','RallyForRestaurants','SupportLocalRestaurants','SupportLocal',\n",
    "              'SupportLocalBusiness','TheGreatAmericanTakeout','CarryOut','OrderIn','CurbSide','CurbSidePickup',\n",
    "              'DineLocal','StillOpen','WereOpen']\n",
    "FOOD_TERMS = [word.lower() for word in FOOD_TERMS]\n",
    "\n",
    "POLITICAL_TERMS = ['trumpownseverydeath','Trumpliedpeopledied','Trumpliesamericansdie','trumpliespeopledie',\n",
    "                   'Wisconsinpandemicvoting','Trumpgenocide','trumppandemic','gopgenocide']\n",
    "POLITICAL_TERMS = [word.lower() for word in POLITICAL_TERMS]\n",
    "\n",
    "STIGMA_TERMS = ['HateIsAVirus','WashTheHate','RacismIsAVirus','IAmNotCOVID19']\n",
    "STIGMA_TERMS = [word.lower() for word in STIGMA_TERMS]\n",
    "\n",
    "CONSPIRACY_TERMS = ['filmyourhospital','filmyourhospitals','filmyourhospitalchallenge','emptyhospital','dempanic',\n",
    "                    'plandemic','5gkills','5gconspiracy']\n",
    "CONSPIRACY_TERMS = [word.lower() for word in CONSPIRACY_TERMS]\n",
    "\n",
    "VACCINE_TERMS = ['vaccine','vaccines','vaccine','vaccines','vaccination','vaccinations','moderna','pfizer',\n",
    "                 'CoronavirusVaccine','antivaxx','antivax','antivaccine','ProSafeVaccine','vaccin','CashingInOnCovid',\n",
    "                 'MyBodyMyChoice','VaccineSafety','NoVaccines','Vax','NoVaccine','vaccineswork','vaccineinjury',\n",
    "                 'vaccinefree','vaccineinjuryawareness','vaccinesharm','vaccinescauseadults','vaccineawareness',\n",
    "                 'vaccinesdontcauseautism','vaccinehoax','DoctorsSpeakUp']\n",
    "VACCINE_TERMS = [word.lower() for word in VACCINE_TERMS]\n",
    "\n",
    "SEARCH_TERMS = GENERAL_TERMS+FOOD_TERMS+POLITICAL_TERMS+STIGMA_TERMS+CONSPIRACY_TERMS+VACCINE_TERMS\n",
    "SEARCH_TERMS_LOWER = [word.lower() for word in SEARCH_TERMS]\n",
    "SEARCH_STRING = '|'.join(SEARCH_TERMS).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column definitions\n",
    "place_cols = ['place_type','place_country','place_state','place_city','place_name',\n",
    "              'bb_sw_lon','bb_sw_lat','bb_nw_lon','bb_nw_lat','bb_ne_lon','bb_ne_lat','bb_se_lon','bb_se_lat']\n",
    "user_cols = ['screen_name','name','description','location','created_at','protected','verified','geo_enabled','default_profile',\n",
    "'statuses_count','favourites_count','friends_count','followers_count','listed_count',\n",
    "'url','profile_image_url_https','profile_background_image_url_https']\n",
    "\n",
    "quote_cols = ['created_at','favorite_count','retweet_count','quote_count','reply_count']\n",
    "quote_display_cols = ['text','created_at','favorite_count','retweet_count','quote_count','reply_count']\n",
    "\n",
    "message_cols = ['created_at','favorite_count','retweet_count','quote_count','reply_count']\n",
    "message_display_cols = ['user_id','place_id','quote_id','coordinates','text',\n",
    "                        'created_at','favorite_count','retweet_count','quote_count','reply_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top level data entities (1 message:1 entity, 1 entity:N messages)\n",
    "place_dict = dict()\n",
    "user_dict = dict()\n",
    "quote_dict = dict()\n",
    "message_dict = dict()\n",
    "# Message data (1 message:N entities, 1 entity:M messages)\n",
    "hashtag_data = []\n",
    "mention_data = []\n",
    "keyword_data = []\n",
    "# Aggregate data\n",
    "hashtag_counter = Counter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class and Function Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a tweet with data for the desired key\n",
    "def get_example(data, query_key, shuffle=False):\n",
    "    if shuffle:\n",
    "        data = data.copy().sample(frac=1)\n",
    "    \n",
    "    for idx,row in data.iterrows():\n",
    "        status = json.loads(row['status'])\n",
    "        entity=None\n",
    "        \n",
    "        if type(query_key)==str:\n",
    "            if query_key in status.keys() and status[query_key] not in [None,[]]:\n",
    "                return status\n",
    "        elif type(query_key)==list:\n",
    "            if query_key[0] in status.keys() and status[query_key[0]] not in [None,[]]:\n",
    "                entity=status[query_key[0]]\n",
    "                for key in query_key[1:]:\n",
    "                    if key in entity.keys() and entity[key] not in [None,[]]:\n",
    "                        entity = entity[key]\n",
    "                    else:\n",
    "                        entity=None\n",
    "                \n",
    "        if entity!=None:\n",
    "            return status\n",
    "    \n",
    "    \n",
    "    print('Could not find example data!')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(data,query_key,return_keys=False):\n",
    "    values = []\n",
    "    for idx,row in data.iterrows():\n",
    "        status = json.loads(row['status'])\n",
    "        \n",
    "        if type(query_key)==str:\n",
    "            if query_key in status.keys() and status[query_key]!=None:\n",
    "                if return_keys:\n",
    "                    for item in status[query_key].keys():\n",
    "                        values.append(item)\n",
    "                else:\n",
    "                    values.append(status[query_key])\n",
    "        elif type(query_key)==list:\n",
    "            if query_key[0] in status.keys() and status[query_key[0]]!=None:\n",
    "                entity=status[query_key[0]]\n",
    "                for key in query_key[1:]:\n",
    "                    if key in entity.keys() and entity[key]!=None:\n",
    "                        entity = entity[key]\n",
    "                if type(entity)==list:\n",
    "                    entity = tuple(entity)\n",
    "                values.append(entity)\n",
    "                \n",
    "    return list(set(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_items(data):\n",
    "\n",
    "    atomic_keys = []\n",
    "    composite_keys = []\n",
    "    composite_dict = dict()\n",
    "    second_level = []\n",
    "\n",
    "    for idx,row in data.iterrows():\n",
    "        status = json.loads(row['status'])\n",
    "        keywords = row['keywords'].split(',')\n",
    "\n",
    "        for key in status.keys():\n",
    "            if type(status[key])==dict:\n",
    "                composite_keys.append(key)\n",
    "                entity = status[key]\n",
    "                if key not in composite_dict.keys():\n",
    "                    composite_dict[key] = list(entity.keys())\n",
    "                else:\n",
    "                    composite_dict[key] = list(set(composite_dict[key] + list(entity.keys())))\n",
    "                for item in entity.keys():\n",
    "                    if type(entity[item])==dict:\n",
    "                        second_level.append((key,item))\n",
    "            else:\n",
    "                atomic_keys.append(key)\n",
    "\n",
    "    atomic_keys = list(set(atomic_keys))\n",
    "    composite_keys = list(set(composite_keys))\n",
    "    second_level = list(set(second_level))\n",
    "    \n",
    "    return atomic_keys,composite_keys,composite_dict,second_level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_data(status):\n",
    "    user_id = status['user']['id_str']\n",
    "    if user_id not in user_dict.keys():\n",
    "        # add user\n",
    "        user_dict[user_id] = [status['user'][key] for key in user_cols]\n",
    "    return user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_place_data(status):\n",
    "    # check for place\n",
    "    if 'place' in status.keys():\n",
    "        place_id = status['place']['id']\n",
    "        if place_id not in place_dict.keys():\n",
    "            # add place\n",
    "            place_state,place_city,place_name = '','',''\n",
    "            place_type = status['place']['place_type']\n",
    "            place_country = status['place']['country_code']\n",
    "            if place_type == 'admin':\n",
    "                place_state = status['place']['name']\n",
    "            elif place_type == 'city':\n",
    "                temp = [item.strip(' ') for item in status['place']['full_name'].split(',')]\n",
    "                place_state = temp[1]\n",
    "                place_city = temp[0]\n",
    "            elif place_type == 'neighborhood':\n",
    "                temp = [item.strip(' ') for item in status['place']['full_name'].split(',')]\n",
    "                place_city = temp[1]\n",
    "                place_name = temp[0]\n",
    "            else:\n",
    "                place_name = status['place']['full_name']\n",
    "            # bounding box\n",
    "            temp = status['place']['bounding_box']['coordinates'][0]\n",
    "            bb_sw_lon,bb_sw_lat = temp[0][0],temp[0][1]\n",
    "            bb_nw_lon,bb_nw_lat = temp[1][0],temp[1][1]\n",
    "            bb_ne_lon,bb_ne_lat = temp[2][0],temp[2][1]\n",
    "            bb_se_lon,bb_se_lat = temp[3][0],temp[3][1]\n",
    "            # insert in dictionary\n",
    "            place_dict[place_id] = [place_type,place_country,place_state,place_city,place_name,\n",
    "                                    bb_sw_lon,bb_sw_lat,bb_nw_lon,bb_nw_lat,\n",
    "                                    bb_ne_lon,bb_ne_lat,bb_se_lon,bb_se_lat]\n",
    "    else:\n",
    "        place_id = ''\n",
    "        \n",
    "    return place_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quote_data(status):\n",
    "    # Check for quote tweet\n",
    "    if 'quoted_status' in status.keys():\n",
    "        quote = status['quoted_status']\n",
    "        quote_id = quote['id_str']\n",
    "        if quote_id not in quote_dict.keys():\n",
    "            # add quote\n",
    "            if 'extended_tweet' in quote.keys():\n",
    "                text = quote['extended_tweet']['full_text']\n",
    "            else:\n",
    "                text = quote['text']\n",
    "            quote_dict[quote_id] = [text] + [quote[key] for key in quote_cols]\n",
    "            \n",
    "    else:\n",
    "        quote_id = ''\n",
    "    \n",
    "    return quote_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_message_data(status,user_id,place_id,quote_id):\n",
    "    message_id = status['id_str']\n",
    "    if message_id not in message_dict.keys():\n",
    "        # add message\n",
    "        if 'extended_tweet' in status.keys():\n",
    "            text = status['extended_tweet']['full_text']\n",
    "        else:\n",
    "            text = status['text']\n",
    "            \n",
    "        if status['coordinates'] == None:\n",
    "            coordinates = np.nan\n",
    "        else:\n",
    "            coordinates = status['coordinates']['coordinates']\n",
    "        message_dict[message_id] = [user_id,place_id,quote_id,coordinates,text] + [status[key] for key in message_cols]\n",
    "    return message_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_auxiliary_data(status,keywords):\n",
    "    message_id = status['id_str']\n",
    "    \n",
    "    # Handle extended tweets\n",
    "    if 'extended_tweet' in status.keys():\n",
    "        hashtags = list(set(item['text'].lower() for item in status['extended_tweet']['entities']['hashtags']))\n",
    "    else:\n",
    "        hashtags = list(set(item['text'].lower() for item in status['entities']['hashtags']))\n",
    "    # Process hashtags\n",
    "    for item in hashtags:\n",
    "        hashtag_data.append([message_id,item])\n",
    "        hashtag_counter[item] += 1\n",
    "    # process keywords\n",
    "    for item in keywords:\n",
    "        keyword_data.append([message_id,item])\n",
    "    # process mentions\n",
    "    # TODO\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_status_data(status,keywords):\n",
    "    # User Data - add error check here and below\n",
    "    user_id = get_user_data(status)\n",
    "    \n",
    "    # Place Data\n",
    "    place_id = get_place_data(status)\n",
    "    \n",
    "    # Quote Data \n",
    "    quote_id = get_quote_data(status)\n",
    "    \n",
    "    # Message Data\n",
    "    message_id = get_message_data(status,user_id,place_id,quote_id)\n",
    "    \n",
    "    # Auxiliary Message Data \n",
    "    get_auxiliary_data(status,keywords)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data):\n",
    "    count = 0\n",
    "    \n",
    "    # Main loop\n",
    "    for idx,row in data.iterrows():\n",
    "        status = json.loads(row['status'])\n",
    "        keywords = row['keywords'].split(',')\n",
    "        \n",
    "        # Process status - add error check here\n",
    "        get_status_data(status,keywords)\n",
    "          \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Raw JSON data\n",
    "data = pd.read_csv(RAW_DATA_PATH + 'raw_data_04202021.csv', names=['status','keywords'], usecols=[1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310711\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>{\"place\": {\"url\": \"https://api.twitter.com/1.1...</td>\n",
       "      <td>corona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>{\"place\": {\"url\": \"https://api.twitter.com/1.1...</td>\n",
       "      <td>covid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              status keywords\n",
       "0  {\"place\": {\"url\": \"https://api.twitter.com/1.1...   corona\n",
       "1  {\"place\": {\"url\": \"https://api.twitter.com/1.1...    covid"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43581\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>location</th>\n",
       "      <th>created_at</th>\n",
       "      <th>protected</th>\n",
       "      <th>verified</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>url</th>\n",
       "      <th>profile_image_url_https</th>\n",
       "      <th>profile_background_image_url_https</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>879728956542472196</td>\n",
       "      <td>BobWitkowsky</td>\n",
       "      <td>BobCat</td>\n",
       "      <td>Disillusioned over the current political clima...</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>Tue Jun 27 15:51:42 +0000 2017</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>9496</td>\n",
       "      <td>6006</td>\n",
       "      <td>5118</td>\n",
       "      <td>5317</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/105944798...</td>\n",
       "      <td>https://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2239734750</td>\n",
       "      <td>SheilaShowPHL</td>\n",
       "      <td>Sheila Hess</td>\n",
       "      <td>CITY REPRESENTATIVE @phillymayor. @PhillyCityR...</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Tue Dec 10 20:35:25 +0000 2013</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>14166</td>\n",
       "      <td>35627</td>\n",
       "      <td>4690</td>\n",
       "      <td>4657</td>\n",
       "      <td>80</td>\n",
       "      <td>None</td>\n",
       "      <td>https://pbs.twimg.com/profile_images/908894334...</td>\n",
       "      <td>https://abs.twimg.com/images/themes/theme14/bg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      screen_name         name  \\\n",
       "879728956542472196   BobWitkowsky       BobCat   \n",
       "2239734750          SheilaShowPHL  Sheila Hess   \n",
       "\n",
       "                                                          description  \\\n",
       "879728956542472196  Disillusioned over the current political clima...   \n",
       "2239734750          CITY REPRESENTATIVE @phillymayor. @PhillyCityR...   \n",
       "\n",
       "                        location                      created_at  protected  \\\n",
       "879728956542472196  Pennsylvania  Tue Jun 27 15:51:42 +0000 2017      False   \n",
       "2239734750          Philadelphia  Tue Dec 10 20:35:25 +0000 2013      False   \n",
       "\n",
       "                    verified  geo_enabled  default_profile  statuses_count  \\\n",
       "879728956542472196     False         True            False            9496   \n",
       "2239734750              True         True            False           14166   \n",
       "\n",
       "                    favourites_count  friends_count  followers_count  \\\n",
       "879728956542472196              6006           5118             5317   \n",
       "2239734750                     35627           4690             4657   \n",
       "\n",
       "                    listed_count   url  \\\n",
       "879728956542472196             3  None   \n",
       "2239734750                    80  None   \n",
       "\n",
       "                                              profile_image_url_https  \\\n",
       "879728956542472196  https://pbs.twimg.com/profile_images/105944798...   \n",
       "2239734750          https://pbs.twimg.com/profile_images/908894334...   \n",
       "\n",
       "                                   profile_background_image_url_https  \n",
       "879728956542472196  https://abs.twimg.com/images/themes/theme1/bg.png  \n",
       "2239734750          https://abs.twimg.com/images/themes/theme14/bg...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df = pd.DataFrame.from_dict(user_dict, orient='index', columns=user_cols)\n",
    "print(len(user_df))\n",
    "user_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2378\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>place_type</th>\n",
       "      <th>place_country</th>\n",
       "      <th>place_state</th>\n",
       "      <th>place_city</th>\n",
       "      <th>place_name</th>\n",
       "      <th>bb_sw_lon</th>\n",
       "      <th>bb_sw_lat</th>\n",
       "      <th>bb_nw_lon</th>\n",
       "      <th>bb_nw_lat</th>\n",
       "      <th>bb_ne_lon</th>\n",
       "      <th>bb_ne_lat</th>\n",
       "      <th>bb_se_lon</th>\n",
       "      <th>bb_se_lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9b977bdde8553e88</td>\n",
       "      <td>city</td>\n",
       "      <td>US</td>\n",
       "      <td>PA</td>\n",
       "      <td>Horsham</td>\n",
       "      <td></td>\n",
       "      <td>-75.1688</td>\n",
       "      <td>40.1569</td>\n",
       "      <td>-75.1688</td>\n",
       "      <td>40.2118</td>\n",
       "      <td>-75.1069</td>\n",
       "      <td>40.2118</td>\n",
       "      <td>-75.1069</td>\n",
       "      <td>40.1569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>e4a0d228eb6be76b</td>\n",
       "      <td>city</td>\n",
       "      <td>US</td>\n",
       "      <td>PA</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td></td>\n",
       "      <td>-75.2803</td>\n",
       "      <td>39.8718</td>\n",
       "      <td>-75.2803</td>\n",
       "      <td>40.1379</td>\n",
       "      <td>-74.9557</td>\n",
       "      <td>40.1379</td>\n",
       "      <td>-74.9557</td>\n",
       "      <td>39.8718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 place_type place_country place_state    place_city  \\\n",
       "9b977bdde8553e88       city            US          PA       Horsham   \n",
       "e4a0d228eb6be76b       city            US          PA  Philadelphia   \n",
       "\n",
       "                 place_name  bb_sw_lon  bb_sw_lat  bb_nw_lon  bb_nw_lat  \\\n",
       "9b977bdde8553e88              -75.1688    40.1569   -75.1688    40.2118   \n",
       "e4a0d228eb6be76b              -75.2803    39.8718   -75.2803    40.1379   \n",
       "\n",
       "                  bb_ne_lon  bb_ne_lat  bb_se_lon  bb_se_lat  \n",
       "9b977bdde8553e88   -75.1069    40.2118   -75.1069    40.1569  \n",
       "e4a0d228eb6be76b   -74.9557    40.1379   -74.9557    39.8718  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "place_df = pd.DataFrame.from_dict(place_dict, orient='index', columns=place_cols)\n",
    "print(len(place_df))\n",
    "place_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42254\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1245757284002627584</td>\n",
       "      <td>This is what the corona virus would look like ...</td>\n",
       "      <td>Thu Apr 02 16:57:36 +0000 2020</td>\n",
       "      <td>3183</td>\n",
       "      <td>430</td>\n",
       "      <td>47</td>\n",
       "      <td>296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1245799250602217473</td>\n",
       "      <td>Sending our love to everyone ‚ù§Ô∏è #crushcovid ht...</td>\n",
       "      <td>Thu Apr 02 19:44:21 +0000 2020</td>\n",
       "      <td>4280</td>\n",
       "      <td>610</td>\n",
       "      <td>94</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  text  \\\n",
       "1245757284002627584  This is what the corona virus would look like ...   \n",
       "1245799250602217473  Sending our love to everyone ‚ù§Ô∏è #crushcovid ht...   \n",
       "\n",
       "                                         created_at  favorite_count  \\\n",
       "1245757284002627584  Thu Apr 02 16:57:36 +0000 2020            3183   \n",
       "1245799250602217473  Thu Apr 02 19:44:21 +0000 2020            4280   \n",
       "\n",
       "                     retweet_count  quote_count  reply_count  \n",
       "1245757284002627584            430           47          296  \n",
       "1245799250602217473            610           94          112  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quote_df = pd.DataFrame.from_dict(quote_dict, orient='index', columns=quote_display_cols)\n",
    "print(len(quote_df))\n",
    "quote_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308631\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>place_id</th>\n",
       "      <th>quote_id</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1245866248635727872</td>\n",
       "      <td>879728956542472196</td>\n",
       "      <td>9b977bdde8553e88</td>\n",
       "      <td>1245757284002627584</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The corona viruse fears catching the Kelly Ann...</td>\n",
       "      <td>Fri Apr 03 00:10:35 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1245866546926243840</td>\n",
       "      <td>2239734750</td>\n",
       "      <td>e4a0d228eb6be76b</td>\n",
       "      <td>1245799250602217473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>#CrushCovid you said it @bryceharper3! üôå And y...</td>\n",
       "      <td>Fri Apr 03 00:11:46 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                user_id          place_id  \\\n",
       "1245866248635727872  879728956542472196  9b977bdde8553e88   \n",
       "1245866546926243840          2239734750  e4a0d228eb6be76b   \n",
       "\n",
       "                                quote_id coordinates  \\\n",
       "1245866248635727872  1245757284002627584         NaN   \n",
       "1245866546926243840  1245799250602217473         NaN   \n",
       "\n",
       "                                                                  text  \\\n",
       "1245866248635727872  The corona viruse fears catching the Kelly Ann...   \n",
       "1245866546926243840  #CrushCovid you said it @bryceharper3! üôå And y...   \n",
       "\n",
       "                                         created_at  favorite_count  \\\n",
       "1245866248635727872  Fri Apr 03 00:10:35 +0000 2020               0   \n",
       "1245866546926243840  Fri Apr 03 00:11:46 +0000 2020               0   \n",
       "\n",
       "                     retweet_count  quote_count  reply_count  \n",
       "1245866248635727872              0            0            0  \n",
       "1245866546926243840              0            0            0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### NEED TO REPULL DATA FOR ALL UNIQUE MESSAGE IDS TO GET UPDATED ENGAGEMENT COUNTS ####\n",
    "message_df = pd.DataFrame.from_dict(message_dict, orient='index', columns=message_display_cols)\n",
    "print(len(message_df))\n",
    "message_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number tweets with geo data: 308631\n",
      "Number tweets with precise coordinates: 22693\n"
     ]
    }
   ],
   "source": [
    "# Geo data\n",
    "print('Number tweets with geo data:',len(message_df))\n",
    "print('Number tweets with precise coordinates:',len(message_df[message_df['coordinates'].notnull()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of hashtags used: 261579\n",
      "Number of unique hashtags: 58581\n",
      "Number of Tweets with hashtags: 84294\n"
     ]
    }
   ],
   "source": [
    "# Hashtags\n",
    "print('Total number of hashtags used:',len(hashtag_data))\n",
    "print('Number of unique hashtags:',len(hashtag_counter))\n",
    "print('Number of Tweets with hashtags:',len(set(item[0] for item in hashtag_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 hashtags:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('covid19', 14638),\n",
       " ('coronavirus', 5292),\n",
       " ('traffic', 2857),\n",
       " ('covid', 2439),\n",
       " ('wearamask', 2044),\n",
       " ('trumpvirus', 1829),\n",
       " ('philadelphia', 1750),\n",
       " ('stayhome', 1728),\n",
       " ('covid_19', 1650),\n",
       " ('quarantine', 1509),\n",
       " ('socialdistancing', 1450),\n",
       " ('staysafe', 1372),\n",
       " ('quarantinelife', 1341),\n",
       " ('pdoh', 1255),\n",
       " ('philly', 1243),\n",
       " ('covid„Éº19', 1187),\n",
       " ('sdoh', 1088),\n",
       " ('trump', 1060),\n",
       " ('pandemic', 1031),\n",
       " ('maskup', 878)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top hashtags\n",
    "num=20\n",
    "print('Top',num,'hashtags:')\n",
    "hashtag_counter.most_common(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update favorite and retweet counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize parameters\n",
    "CHUNK = 100\n",
    "status_updates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 statuses processed...\n",
      "10000 statuses processed...\n",
      "20000 statuses processed...\n",
      "30000 statuses processed...\n",
      "40000 statuses processed...\n",
      "50000 statuses processed...\n",
      "60000 statuses processed...\n",
      "70000 statuses processed...\n",
      "80000 statuses processed...\n",
      "90000 statuses processed...\n",
      "100000 statuses processed...\n",
      "110000 statuses processed...\n",
      "120000 statuses processed...\n",
      "130000 statuses processed...\n",
      "140000 statuses processed...\n",
      "150000 statuses processed...\n",
      "160000 statuses processed...\n",
      "170000 statuses processed...\n",
      "180000 statuses processed...\n",
      "190000 statuses processed...\n",
      "200000 statuses processed...\n",
      "210000 statuses processed...\n",
      "220000 statuses processed...\n",
      "230000 statuses processed...\n",
      "240000 statuses processed...\n",
      "250000 statuses processed...\n",
      "260000 statuses processed...\n",
      "270000 statuses processed...\n",
      "280000 statuses processed...\n",
      "290000 statuses processed...\n",
      "300000 statuses processed...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-0483786b3d15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# update message_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mmessage_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'favorite_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'favorite_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mmessage_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'retweet_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'retweet_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    555\u001b[0m                 \u001b[0;31m# scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m                     \u001b[0msetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36msetter\u001b[0;34m(item, v)\u001b[0m\n\u001b[1;32m    488\u001b[0m                     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m                     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m                     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m                     \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36msetitem\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"setitem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mputmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m    436\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36msetitem\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    941\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m         \u001b[0;31m# coerce and try to infer the dtypes of the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_coerce_and_cast_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_try_coerce_and_cast_result\u001b[0;34m(self, result, dtype)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_coerce_and_cast_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_coerce_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_cast_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    748\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36m_try_cast_result\u001b[0;34m(self, result, dtype)\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;31m# may need to change the dtype here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_downcast_to_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_coerce_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_downcast_to_dtype\u001b[0;34m(result, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"infer\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0minferred_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minferred_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"boolean\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                 \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"bool\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get status updates\n",
    "for i in range(len(status_updates),len(message_df),CHUNK):\n",
    "    id_list = message_df.iloc[i:i+CHUNK,:].index.to_list()\n",
    "    status_updates += api.statuses_lookup(id_list)\n",
    "    time.sleep(2)\n",
    "    if i%10000 == 0:\n",
    "        print(i, 'statuses processed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 statuses processed...\n",
      "10000 statuses processed...\n",
      "20000 statuses processed...\n",
      "30000 statuses processed...\n",
      "40000 statuses processed...\n",
      "50000 statuses processed...\n",
      "60000 statuses processed...\n",
      "70000 statuses processed...\n",
      "80000 statuses processed...\n",
      "90000 statuses processed...\n",
      "100000 statuses processed...\n",
      "110000 statuses processed...\n",
      "120000 statuses processed...\n",
      "130000 statuses processed...\n",
      "140000 statuses processed...\n",
      "150000 statuses processed...\n",
      "160000 statuses processed...\n",
      "170000 statuses processed...\n",
      "180000 statuses processed...\n",
      "190000 statuses processed...\n",
      "200000 statuses processed...\n",
      "210000 statuses processed...\n",
      "220000 statuses processed...\n",
      "230000 statuses processed...\n",
      "240000 statuses processed...\n",
      "250000 statuses processed...\n",
      "260000 statuses processed...\n"
     ]
    }
   ],
   "source": [
    "# Get update counts and update message df\n",
    "count = 0\n",
    "for item in status_updates:\n",
    "    key = item.id_str\n",
    "    favorite = item.favorite_count\n",
    "    retweet = item.retweet_count\n",
    "    message_df.at[key,'favorite_count'] = favorite\n",
    "    message_df.at[key,'retweet_count'] = retweet\n",
    "    if count%10000 == 0:\n",
    "        print(count, 'statuses processed...')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Augment Keyword Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_dict = dict()\n",
    "not_found = []\n",
    "\n",
    "# Add keyword categories\n",
    "for item in keyword_data:\n",
    "    if item[1].lower() in GENERAL_TERMS:\n",
    "        item.append('general')\n",
    "    elif item[1].lower() in FOOD_TERMS:\n",
    "        item.append('food')\n",
    "    elif item[1].lower() in POLITICAL_TERMS:\n",
    "        item.append('political')\n",
    "    elif item[1].lower() in STIGMA_TERMS:\n",
    "        item.append('stigma')\n",
    "    elif item[1].lower() in CONSPIRACY_TERMS:\n",
    "        item.append('conspiracy')\n",
    "    elif item[1].lower() in VACCINE_TERMS:\n",
    "        item.append('vaccine')\n",
    "    else:\n",
    "        item.append('none')\n",
    "        not_found.append(item)\n",
    "\n",
    "# Create keyword data structures\n",
    "keyword_df = pd.DataFrame(keyword_data, columns=['status_id','keyword','category'])\n",
    "for key,group in keyword_df.groupby(['status_id']):\n",
    "    keyword_dict[key] = {'keywords':set(group.keyword),'categories':set(group.category)}\n",
    "    \n",
    "# Filtered keyword lists\n",
    "keywords_general = [item for item in keyword_data if item[2] == 'general']\n",
    "keywords_general_ids = set(item[0] for item in keywords_general)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442088\n",
      "459006\n",
      "459006\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1245866248635727872</td>\n",
       "      <td>corona</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1245866546926243840</td>\n",
       "      <td>covid</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1245866702316769281</td>\n",
       "      <td>corona</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1245866951127093248</td>\n",
       "      <td>coronavirus</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1245866951127093248</td>\n",
       "      <td>corona</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             status_id      keyword category\n",
       "0  1245866248635727872       corona  general\n",
       "1  1245866546926243840        covid  general\n",
       "2  1245866702316769281       corona  general\n",
       "3  1245866951127093248  coronavirus  general\n",
       "4  1245866951127093248       corona  general"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(set([tuple(item) for item in keyword_data])))\n",
    "print(len(keyword_data))\n",
    "print(len(keyword_df))\n",
    "keyword_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hashtag Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtag_df = pd.DataFrame(hashtag_data, columns=['status_id','hashtag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258146\n",
      "261579\n",
      "261579\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1245866546926243840</td>\n",
       "      <td>crushcovid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1245866546926243840</td>\n",
       "      <td>hungerrelief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1245866546926243840</td>\n",
       "      <td>thankyouphilly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1245866702316769281</td>\n",
       "      <td>coronapocalypse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1245866702316769281</td>\n",
       "      <td>day22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             status_id          hashtag\n",
       "0  1245866546926243840       crushcovid\n",
       "1  1245866546926243840     hungerrelief\n",
       "2  1245866546926243840   thankyouphilly\n",
       "3  1245866702316769281  coronapocalypse\n",
       "4  1245866702316769281            day22"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(set([tuple(item) for item in hashtag_data])))\n",
    "print(len(hashtag_data))\n",
    "print(len(hashtag_df))\n",
    "hashtag_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Top Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE1: some keywords are pulling invalid tweets - for example \"ppe\" is pulling aPPEaling and haPPEning\n",
    "    # need to fix PPE keyword - add space before - ' ppe' instead of 'ppe'\n",
    "# NOTE2: repeat items are discarded for dict data but not for list data\n",
    "    # for example, duplicate messages are not in message df but appear in hashtag df (see code below to fix)\n",
    "# NOTE3: keyword and hashtag fixes and augmentations can be added to the processing functions above\n",
    "    \n",
    "# Filter data\n",
    "use_ids = set(keyword_df[keyword_df['keyword']!='ppe'].status_id)\n",
    "use_df = message_df[message_df.index.isin(use_ids)]\n",
    "\n",
    "# Top 20 favorites\n",
    "fav_name = SUMMARY_DATA_PATH + 'top20_favorite_filtered_' + str(datetime.datetime.now().date()).replace('-','') + '.csv'\n",
    "fav_df = use_df.sort_values('favorite_count', ascending=False).iloc[0:20,:]\n",
    "fav_df.to_csv(fav_name)\n",
    "\n",
    "# Top 20 retweets\n",
    "re_name = SUMMARY_DATA_PATH + 'top20_retweet_filtered_' + str(datetime.datetime.now().date()).replace('-','') + '.csv'\n",
    "re_df = use_df.sort_values('retweet_count', ascending=False).iloc[0:20,:]\n",
    "re_df.to_csv(re_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status_id</th>\n",
       "      <th>hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>176637</td>\n",
       "      <td>1314953231697616897</td>\n",
       "      <td>bidenwillcrushcovid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  status_id              hashtag\n",
       "176637  1314953231697616897  bidenwillcrushcovid"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtag_df[hashtag_df['status_id'].isin(fav_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaccine_ids = set(keyword_df[keyword_df['category']=='vaccine'].status_id)\n",
    "vaccine_df = message_df[message_df.index.isin(vaccine_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16396\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>place_id</th>\n",
       "      <th>quote_id</th>\n",
       "      <th>coordinates</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>reply_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1338608164183429131</td>\n",
       "      <td>16379909</td>\n",
       "      <td>7c6845d4f5897da3</td>\n",
       "      <td>1338074061738545156</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Last sign in this: ‚ÄúNo Science, No Shutdown‚Äù P...</td>\n",
       "      <td>Mon Dec 14 22:13:51 +0000 2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1338608371679842305</td>\n",
       "      <td>2941293160</td>\n",
       "      <td>e4a0d228eb6be76b</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Anybody worried about the virus should get the...</td>\n",
       "      <td>Mon Dec 14 22:14:40 +0000 2020</td>\n",
       "      <td>57</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1338609203024367616</td>\n",
       "      <td>411627211</td>\n",
       "      <td>e4a0d228eb6be76b</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>Me after my vaccine enjoying a blacked out cig...</td>\n",
       "      <td>Mon Dec 14 22:17:58 +0000 2020</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1338609357546803201</td>\n",
       "      <td>1186424808663388160</td>\n",
       "      <td>3f5897b87d2bf56c</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>@SenTedCruz sir there should be a resalution b...</td>\n",
       "      <td>Mon Dec 14 22:18:35 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1338611087244210176</td>\n",
       "      <td>1146608039442755584</td>\n",
       "      <td>28573a4eb6bb7ae3</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>@HillaryClinton Hillary...will you take the va...</td>\n",
       "      <td>Mon Dec 14 22:25:28 +0000 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 user_id          place_id  \\\n",
       "1338608164183429131             16379909  7c6845d4f5897da3   \n",
       "1338608371679842305           2941293160  e4a0d228eb6be76b   \n",
       "1338609203024367616            411627211  e4a0d228eb6be76b   \n",
       "1338609357546803201  1186424808663388160  3f5897b87d2bf56c   \n",
       "1338611087244210176  1146608039442755584  28573a4eb6bb7ae3   \n",
       "\n",
       "                                quote_id coordinates  \\\n",
       "1338608164183429131  1338074061738545156         NaN   \n",
       "1338608371679842305                              NaN   \n",
       "1338609203024367616                              NaN   \n",
       "1338609357546803201                              NaN   \n",
       "1338611087244210176                              NaN   \n",
       "\n",
       "                                                                  text  \\\n",
       "1338608164183429131  Last sign in this: ‚ÄúNo Science, No Shutdown‚Äù P...   \n",
       "1338608371679842305  Anybody worried about the virus should get the...   \n",
       "1338609203024367616  Me after my vaccine enjoying a blacked out cig...   \n",
       "1338609357546803201  @SenTedCruz sir there should be a resalution b...   \n",
       "1338611087244210176  @HillaryClinton Hillary...will you take the va...   \n",
       "\n",
       "                                         created_at  favorite_count  \\\n",
       "1338608164183429131  Mon Dec 14 22:13:51 +0000 2020               1   \n",
       "1338608371679842305  Mon Dec 14 22:14:40 +0000 2020              57   \n",
       "1338609203024367616  Mon Dec 14 22:17:58 +0000 2020              17   \n",
       "1338609357546803201  Mon Dec 14 22:18:35 +0000 2020               0   \n",
       "1338611087244210176  Mon Dec 14 22:25:28 +0000 2020               0   \n",
       "\n",
       "                     retweet_count  quote_count  reply_count  \n",
       "1338608164183429131              0            0            0  \n",
       "1338608371679842305             20            0            0  \n",
       "1338609203024367616              0            0            0  \n",
       "1338609357546803201              0            0            0  \n",
       "1338611087244210176              0            0            0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(vaccine_df))\n",
    "vaccine_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308631\n",
      "247430\n"
     ]
    }
   ],
   "source": [
    "print(len(message_df))\n",
    "print(len(use_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save base data\n",
    "user_df.to_csv(MASTER_DATA_PATH + 'users_tristate_' + str(datetime.datetime.now().date()).replace('-','') + '.csv' )\n",
    "place_df.to_csv(MASTER_DATA_PATH + 'places_tristate_' + str(datetime.datetime.now().date()).replace('-','') + '.csv' )\n",
    "quote_df.to_csv(MASTER_DATA_PATH + 'quotes_tristate_' + str(datetime.datetime.now().date()).replace('-','') + '.csv' )\n",
    "\n",
    "message_df.to_csv(MASTER_DATA_PATH + 'messages_tristate_ppe_' + str(datetime.datetime.now().date()).replace('-','') + '.csv' )\n",
    "use_df.to_csv(MASTER_DATA_PATH + 'messages_tristate_' + str(datetime.datetime.now().date()).replace('-','') + '.csv' )\n",
    "vaccine_df.to_csv(MASTER_DATA_PATH + 'messages_tristate_vaccine_' + str(datetime.datetime.now().date()).replace('-','') + '.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save auxiliary data\n",
    "keyword_df.to_csv(MASTER_DATA_PATH + 'keywords_tristate_' + str(datetime.datetime.now().date()).replace('-','') + '.csv')\n",
    "hashtag_df.to_csv(MASTER_DATA_PATH + 'hashtags_tristate_' + str(datetime.datetime.now().date()).replace('-','') + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Misc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim LDA Testing\n",
    "* Use mallet on WWBP server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.test.utils import common_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = gensim.models.ldamodel.LdaModel(common_corpus, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[(2, 0.774994), (5, 0.025002684), (4, 0.025001716), (9, 0.02500145), (0, 0.02500002), (1, 0.02500002), (3, 0.02500002), (7, 0.02500002), (6, 0.025000019), (8, 0.025000019)]\n",
      "\n",
      "0\n",
      "(2, 0.774994)\n"
     ]
    }
   ],
   "source": [
    "for i, row in enumerate(lda[common_corpus]):\n",
    "    row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "    print(i)\n",
    "    print(row)\n",
    "    print()\n",
    "    for j, (topic_num, prop_topic) in enumerate(row):\n",
    "        print(j)\n",
    "        print((topic_num, prop_topic))\n",
    "        wp = lda.show_topic(topic_num)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## kw-first vs bb-first filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "atomic_keys,composite_keys,composite_dict,second_level = get_dict_items(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get examples\n",
    "key = ['quoted_status']\n",
    "value = None\n",
    "found=False\n",
    "count=0\n",
    "while(not found):\n",
    "    status = get_example(data=data,query_key=key,shuffle=True)\n",
    "    if status != None:\n",
    "        found=True\n",
    "    elif count >= 5:\n",
    "        found=True\n",
    "        print('Search failed!')\n",
    "    count +=1\n",
    "status==None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[39.74808776, -75.21749677]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status['geo']['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-75.21749677, 39.74808776]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status['coordinates']['coordinates']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['display_text_range', 'entities', 'full_text', 'extended_entities'])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status['quoted_status']['extended_tweet'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['media', 'symbols', 'hashtags', 'user_mentions', 'urls'])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status['quoted_status']['extended_tweet']['entities'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['symbols', 'hashtags', 'user_mentions', 'urls'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "status['quoted_status']['entities'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<a href=\"http://foursquare.com\" rel=\"nofollow\">Foursquare</a>',\n",
       " '<a href=\"http://instagram.com\" rel=\"nofollow\">Instagram</a>',\n",
       " '<a href=\"http://itunes.apple.com/us/app/twitter/id409789998?mt=12\" rel=\"nofollow\">Twitter for Mac</a>',\n",
       " '<a href=\"http://tapbots.com/tweetbot\" rel=\"nofollow\">Tweetbot for iŒüS</a>',\n",
       " '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>',\n",
       " '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>',\n",
       " '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
       " '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       " '<a href=\"http://ubersocial.com\" rel=\"nofollow\">UberSocial for Android</a>',\n",
       " '<a href=\"http://www.echofon.com/\" rel=\"nofollow\">Echofon</a>',\n",
       " '<a href=\"http://www.recruitology.com\" rel=\"nofollow\">Recruitology</a>',\n",
       " '<a href=\"http://www.squarespace.com\" rel=\"nofollow\">Squarespace</a>',\n",
       " '<a href=\"http://www.tweetcaster.com\" rel=\"nofollow\">TweetCaster for Android</a>',\n",
       " '<a href=\"https://511ny.org\" rel=\"nofollow\">511NY-Tweets</a>',\n",
       " '<a href=\"https://app.agorapulse.com\" rel=\"nofollow\">AgoraPulse Manager</a>',\n",
       " '<a href=\"https://iwaspoisoned.com\" rel=\"nofollow\">IWPTweets</a>',\n",
       " '<a href=\"https://mesonet.agron.iastate.edu/projects/iembot/\" rel=\"nofollow\">iembot</a>',\n",
       " '<a href=\"https://onloft.com/tweetlogix\" rel=\"nofollow\">Tweetlogix</a>',\n",
       " '<a href=\"https://sproutsocial.com\" rel=\"nofollow\">Sprout Social</a>',\n",
       " '<a href=\"https://tapbots.com/software/tweetbot/mac\" rel=\"nofollow\">Tweetbot for Mac</a>',\n",
       " '<a href=\"https://tweet.photo\" rel=\"nofollow\">TWEET.PHOTO</a>',\n",
       " '<a href=\"https://twitterrific.com/ios\" rel=\"nofollow\">Twitterrific for iOS</a>',\n",
       " '<a href=\"https://untappd.com\" rel=\"nofollow\">Untappd</a>',\n",
       " '<a href=\"https://www.careerarc.com\" rel=\"nofollow\">CareerArc 2.0</a>',\n",
       " '<a href=\"https://www.corelistingmachine.com/\" rel=\"nofollow\">CORE ListingMachine</a>',\n",
       " '<a href=\"https://www.hootsuite.com\" rel=\"nofollow\">Hootsuite Inc.</a>',\n",
       " '<a href=\"https://www.rachelbitting.com/twitter\" rel=\"nofollow\">Philly History Photos</a>']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get possible values\n",
    "values = get_values(data,'source',return_keys=False)\n",
    "sorted(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regarding kw-first filtering and retweets:\n",
    "# identify location/coordinate source for RT's (coordinates, place info, user defined loc: possibly only user-defined)\n",
    "# if loc/coord info, determne if in bb\n",
    "# else, determine if posted by user from bb (via bb-first filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unused / Deprecated Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "* geo = lat/lon, coordinates = lon/lat, identical otherwise\n",
    "    * (on map) right-->less negative, up-->more positive\n",
    "* place:\n",
    "    * bb coordinate order: sw,nw,ne,se\n",
    "    * place types = 'admin', 'city', 'neighborhood', 'poi'\n",
    "        * admin: state\n",
    "        * city: city,state\n",
    "        * neighborhood: name,city\n",
    "        * poi: name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "# Get update counts\n",
    "for item in status_updates:\n",
    "    key = item.id_str\n",
    "    favorite = item.favorite_count\n",
    "    retweet = item.retweet_count\n",
    "    results[key] = {'favorite_count':favorite,'retweet_count':retweet}\n",
    "\n",
    "# update message_df\n",
    "for key in results:\n",
    "    message_df.loc[key,'favorite_count'] = results[key]['favorite_count']\n",
    "    message_df.loc[key,'retweet_count'] = results[key]['retweet_count']\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
